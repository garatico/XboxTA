---
title: "XboxTA"
author: "Giovanni Aratico"
date: "2023-05-25"
output: html_document
---
```{r Setup, include=FALSE} 
set.seed(196)
library(tidyverse)
library(tidymodels)
library(lubridate)
library(forecast)
library(shiny)
library(xgboost)
library(data.table)
library(caret)
library(stats)

source("./src/r/file.R")
source("./src/r/plots/plots.R")
source("./src/r/transformations/feature_transformations.R")
source("./src/r/variables/variables.R")
source("./src/r/models/models.R")
```

Gets file directories of all CSVs to pull for analysis.
```{r File Directories / Manifest}
set.seed(196)
directory_df = create_file_directory()
#lb_df = read.csv("./data/leaderboard/leaderboard.csv")
#achievements_manifest = read.csv("./data/manifest/achievements_manifest.csv")

# Sample and sort gamers
rnd_gamer_sample = sample_random_gamers(200, directory_df = directory_df)
rnd_gamer_sample = lapply(rnd_gamer_sample, function(x) x[order(rnd_gamer_sample[[3]])])

rm(create_file_directory)
```

```{r Feature Transformations}
#lb_df = lb_feature_transformations(lb_df)
rnd_gamer_sample[[1]] = achievement_transform_dates(rnd_gamer_sample[[1]])
rnd_gamer_sample[[2]] = games_transform_hours(rnd_gamer_sample[[2]])
```

```{r Metrics Preprocessing (Total / Frequency)}
print(paste("TOTAL OBSERVATIONS: ", get_total_observations(rnd_gamer_sample[[1]])))
metrics_df = process_metrics_df(rnd_gamer_sample, directory_df)

frequency_dfs = achievement_calculate_frequencies(rnd_gamer_sample)
frequency_combined_df = bind_rows(frequency_dfs, .id = "data_frame_id")
frequency_combined_df$data_frame_id = as.numeric(frequency_combined_df$data_frame_id)
```

```{r Metrics Preprocessing (Daily Achievements)}
da_df = calculate_daily_achievements(frequency_combined_df)
da_df = da_fill_dates2(da_df)

da_profiles = da_split_by_profile2(da_df)
da_profiles = da_profiles_set_churn(da_profiles)
da_profiles = da_profiles_set_days_existence(da_profiles)
da_profiles = calculate_daily_lt_eir(da_profiles)
da_profiles = calculate_weekly_eir_all2(da_profiles)
da_profiles = calculate_monthly_eir_all2(da_profiles)
```

```{r EDA Leaderboard}
plot_lb_range(lb_df, "Score", 0, 4000000, 50000, 1000000)

plot_lb_range(lb_df, "Score", 0, 250000, 10000, 25000)
plot_lb_range(lb_df, "Score", 250000, 500000, 10000, 25000)
plot_lb_range(lb_df, "Score", 500000, 1000000, 50000, 50000)
plot_lb_range(lb_df, "Score", 1000000, 2000000, 50000, 100000)
```

```{r EDA Profiles Plot}
# Define UI
ui <- fluidPage(
  titlePanel("Gamer Achievement Frequencies"),
  
  sidebarLayout(
    sidebarPanel(
      numericInput("index", "Select Frequency Index",
                   value = 1, min = 1, max = length(frequency_dfs)),
      radioButtons("plotType", "Select Plot Type",
                  choices = c("Year", "Month", "Month-Year", "Week", "Weekday"),
                  selected = "Year")
    ),
    
    mainPanel(
      plotOutput("achievementPlot")
    )
  )
)

# Define server
server <- function(input, output) {
  
  # Render plot based on selected plot type and frequency index
  output$achievementPlot <- renderPlot({
    index <- input$index
    plotType <- input$plotType
    
    # Choose the appropriate plot function based on the selected plot type
    if (plotType == "Year") {
      plot_gamer_achievement_freq_year(frequency_dfs[[index]])
    } else if (plotType == "Month") {
      plot_gamer_achievement_freq_month(frequency_dfs[[index]])
    } else if (plotType == "Month-Year") {
      plot_gamer_achievement_freq_month_year(frequency_dfs[[index]])
    } else if (plotType == "Week") {
      plot_gamer_achievement_freq_week(frequency_dfs[[index]])
    } else if (plotType == "Weekday") {
      plot_gamer_achievement_freq_weekday(frequency_dfs[[index]])
    }
  })
}

# Run the app
shinyApp(ui = ui, server = server)
```

```{r EDA Profiles Achievement Variables Plots}
# Plot histogram of churned with different colors for TRUE, FALSE, and NA
ggplot(metrics_df, aes(x = churned, fill = factor(churned))) +
  geom_bar(color = "white") +
  scale_fill_manual(values = c("darkgreen", "darkred", "gray")) +
  labs(title = "Churned Histogram", x = "Churned (365 days since last achievement)", y = "Count")

ggplot(metrics_df, aes(x = longest_streak, fill = factor(longest_streak))) +
  geom_bar(color = "white") +
  labs(title = "Streak Histogram", x = "Longest Streak (in Days)", y = "Count")

# Scatter plot
ggplot(metrics_df, aes(x = longest_gap_within, y = total_game_time_minutes)) +
  geom_point() +
  labs(x = "Longest Gap Within", y = "Total Game Time (Minutes)") +
  ggtitle("Scatter Plot: Longest Gap Within vs. Total Game Time (Minutes)")

ggplot(metrics_df, aes(x = average_interval, y = total_game_time_minutes)) +
  geom_point() +
  labs(x = "Average Interval between Achievements (Daily) ", y = "Total Game Time (Minutes)") +
  ggtitle("Scatter Plot: Average Interval between Achievements (Daily) vs. Total Game Time (Minutes)")

ggplot(metrics_df, aes(x = median_interval, y = total_game_time_minutes)) +
  geom_point() +
  labs(x = "Median Interval between Achievements (Daily) ", y = "Total Game Time (Minutes)") +
  ggtitle("Scatter Plot: Median Interval between Achievements (Daily) vs. Total Game Time (Minutes)")

```

```{r RQ1 : Time Series Decomposition}
ts_profiles <- lapply(seq_along(da_profiles), function(i) {
  profile <- da_profiles[[i]]
  profile <- profile %>% arrange(date)

  ts_objs <- list(
    ts(profile$daily_lt_eir, frequency = 366, start = c(profile$year[1], profile$day_of_year[1])),
    ts(profile$weekly_eir, frequency = 366, start = c(profile$year[1], profile$week[1])),
    ts(profile$monthly_eir, frequency = 366, start = c(profile$year[1], profile$month.x[1])),
    ts(profile$days_since_achievement, frequency = 366, start = c(profile$year[1], profile$day_of_year[1])),
    ts(profile$churn_binary, frequency = 366, start = c(profile$year[1], profile$day_of_year[1]))
  )
  
  decompositions <- lapply(ts_objs, function(ts_obj) {
    if (length(ts_obj) >= 2 * 366) {
      decompose(ts_obj)
    } else {
      NULL
    }
  })
  
  if (all(sapply(decompositions, is.null))) {
    print(paste("Insufficient data for profile", i, "- skipping decomposition."))
    return(NULL)
  } else {
    return(list(
      profile = profile,
      ts = ts_objs,
      decomposition = decompositions
    ))
  }
})

```

```{r RQ1 : Time Series Decomposition Plots Shiny}
# Define UI
ui <- fluidPage(
  titlePanel("Time Series Decomposition Plots"),
  sidebarLayout(
    sidebarPanel(
      selectInput("profile", "Select Profile:", choices = seq_along(ts_profiles), selected = ts_profiles[[1]], width = "25%")
    ),
    mainPanel(
      plotOutput("plot1"),
      plotOutput("plot2"),
      plotOutput("plot3"),
      plotOutput("plot4")
    )
  )
)

# Define server
server <- function(input, output) {
  output$plot1 <- renderPlot({
    profile <- ts_profiles[[as.numeric(input$profile)]]
    plot_data <- data.frame(
      date = time(profile$ts[[1]]),
      stringsAsFactors = FALSE
    )
    plot_data$original1 <- profile$ts[[1]]
    plot_data$trend1 <- profile$decomposition[[1]][["trend"]]
    plot_data$seasonal1 <- profile$decomposition[[1]][["seasonal"]]
    plot_data$residual1 <- profile$decomposition[[1]][["random"]]
    
    ggplot(plot_data, aes(x = date)) +
      geom_line(aes(y = original1, color = "Original")) +
      geom_line(aes(y = trend1, color = "Trend")) +
      geom_line(aes(y = seasonal1, color = "Seasonal")) +
      geom_line(aes(y = residual1, color = "Residual")) +
      labs(x = "Date", y = "Value", color = "Component") +
      scale_color_manual(values = c("Original" = "black", "Trend" = "blue",
                                    "Seasonal" = "red", "Residual" = "green")) +
      facet_wrap(~ "Time Series 1: Daily Lifetime EIR", ncol = 1) +
      theme_minimal()
  })
  
  output$plot2 <- renderPlot({
    profile <- ts_profiles[[as.numeric(input$profile)]]
    plot_data <- data.frame(
      date = time(profile$ts[[2]]),
      stringsAsFactors = FALSE
    )
    plot_data$original2 <- profile$ts[[2]]
    plot_data$trend2 <- profile$decomposition[[2]][["trend"]]
    plot_data$seasonal2 <- profile$decomposition[[2]][["seasonal"]]
    plot_data$residual2 <- profile$decomposition[[2]][["random"]]
    
    ggplot(plot_data, aes(x = date)) +
      geom_line(aes(y = original2, color = "Original")) +
      geom_line(aes(y = trend2, color = "Trend")) +
      geom_line(aes(y = seasonal2, color = "Seasonal")) +
      geom_line(aes(y = residual2, color = "Residual")) +
      labs(x = "Date", y = "Value", color = "Component") +
      scale_color_manual(values = c("Original" = "black", "Trend" = "blue",
                                    "Seasonal" = "red", "Residual" = "green")) +
      facet_wrap(~ "Time Series 2: Weekly EIR", ncol = 1) +
      theme_minimal()
  })
  
  output$plot3 <- renderPlot({
    profile <- ts_profiles[[as.numeric(input$profile)]]
    plot_data <- data.frame(
      date = time(profile$ts[[3]]),
      stringsAsFactors = FALSE
    )
    plot_data$original3 <- profile$ts[[3]]
    plot_data$trend3 <- profile$decomposition[[3]][["trend"]]
    plot_data$seasonal3 <- profile$decomposition[[3]][["seasonal"]]
    plot_data$residual3 <- profile$decomposition[[3]][["random"]]
    
    ggplot(plot_data, aes(x = date)) +
      geom_line(aes(y = original3, color = "Original")) +
      geom_line(aes(y = trend3, color = "Trend")) +
      geom_line(aes(y = seasonal3, color = "Seasonal")) +
      geom_line(aes(y = residual3, color = "Residual")) +
      labs(x = "Date", y = "Value", color = "Component") +
      scale_color_manual(values = c("Original" = "black", "Trend" = "blue",
                                    "Seasonal" = "red", "Residual" = "green")) +
      facet_wrap(~ "Time Series 3: Monthly EIR", ncol = 1) +
      theme_minimal()
  })
  
  output$plot4 <- renderPlot({
    profile <- ts_profiles[[as.numeric(input$profile)]]
    plot_data <- data.frame(
      date = time(profile$ts[[4]]),
      stringsAsFactors = FALSE
    )
    plot_data$original4 <- profile$ts[[4]]
    plot_data$trend4 <- profile$decomposition[[4]][["trend"]]
    plot_data$seasonal4 <- profile$decomposition[[4]][["seasonal"]]
    plot_data$residual4 <- profile$decomposition[[4]][["random"]]
    
    ggplot(plot_data, aes(x = date)) +
      geom_line(aes(y = original4, color = "Original")) +
      geom_line(aes(y = trend4, color = "Trend")) +
      geom_line(aes(y = seasonal4, color = "Seasonal")) +
      geom_line(aes(y = residual4, color = "Residual")) +
      labs(x = "Date", y = "Value", color = "Component") +
      scale_color_manual(values = c("Original" = "black", "Trend" = "blue",
                                    "Seasonal" = "red", "Residual" = "green")) +
      facet_wrap(~ "Time Series 4: Days Since Achievement Earned", ncol = 1) +
      theme_minimal()
  })
}

# Run the Shiny app
shinyApp(ui = ui, server = server)



```

```{r RQ1 : Model Preparation}
ts_profiles <- ts_profiles %>% keep(~ !is.null(.))

# Initialize empty lists for data and dtrain
t1_data_list <- list()
t1_dtrain_list <- list()

t2_data_list = list()
t2_dtrain_list = list()

t3_data_list = list()
t3_dtrain_list = list()

t4_data_list = list()
t4_dtrain_list = list()

t5_data_list = list()
t5_dtrain_list = list()

for (i in 1:length(ts_profiles)) {
  for (j in 1:5) {  # Loop over target variables (j = 1 for ts[[1]], j = 2 for ts[[2]])
    # Extract the target variable (daily_lt_eir) and create lagged variables as features
    target <- as.vector(ts_profiles[[i]][["ts"]][[j]])
    # Add a small constant to handle zero values and apply log transformation
    #target_transformed <- log(target + 1e-6)
    lag_1day = lag(target, 1)
    lag_1week = lag(target, 7)
    lag_2week = lag(target, 14)
    lag_1month = lag(target, 28)
    year = ts_profiles[[i]][["profile"]][["year"]]
    month.x = ts_profiles[[i]][["profile"]][["month.x"]]
    day_of_year = ts_profiles[[i]][["profile"]][["day_of_year"]]
    week = ts_profiles[[i]][["profile"]][["week"]]
    
    # Combine the features and target into a data frame
    data <- data.frame(target, year, month.x, day_of_year, week, lag_1day, lag_1week, lag_2week, lag_1month)
    data <- na.omit(data)  # Remove rows with missing values
    
    # Convert the data to DMatrix format
    dtrain <- xgb.DMatrix(data = as.matrix(data[, -1]), label = data[, 1])
    
    # Add the data and dtrain to their respective lists
    if (j == 1) {
      t1_data_list[[i]] <- data
      t1_dtrain_list[[i]] <- dtrain
    } else if (j == 2) {
      t2_data_list[[i]] <- data
      t2_dtrain_list[[i]] <- dtrain
    } else if (j == 3) {
      t3_data_list[[i]] <- data
      t3_dtrain_list[[i]] <- dtrain
    } else if (j == 4) {
      t4_data_list[[i]] <- data
      t4_dtrain_list[[i]] <- dtrain
    } else if (j == 5) {
      t5_data_list[[i]] <- data
      t5_dtrain_list[[i]] <- dtrain
    }
  }
}

```

```{r RQ1 : Cross Validation Create Folds}
data_t1_97 = t1_data_list[[97]]
dtrain_t1_97 = t1_dtrain_list[[97]]

data_t5_97 = t5_data_list[[97]]
dtrain_t5_97 = t5_dtrain_list[[97]]

t1_25fold_full = get_cv_folds(t1_data_list, 25)
t5_25fold_full = get_cv_folds(t5_data_list, 25)

```

```{r RQ1 : Model Train}
# Initialize empty lists to store predictions and performance metrics
all_predictions <- list()
all_rmse <- numeric(length(t1_25fold_full[[97]]))
all_mape <- numeric(length(t1_25fold_full[[97]]))
all_smape <- numeric(length(t1_25fold_full[[97]]))

# Assuming you have an xgb.DMatrix called "dtrain"
params <- list(
  objective = "reg:squarederror",
  eval_metric = "rmse",
  max_depth = 5,
  eta = 0.1,
  subsample = 0.8,
  colsample_bytree = 0.8
)
# Initialize an empty list to store the trained models
t1_models <- list()

# Iterate over the folds
for (i in 1:length(t1_25fold_full[[97]])) {
  # Get the training set and corresponding test set for this fold
  train_indices <- t1_25fold_full[[97]][[i]][["train"]]
  test_indices <- t1_25fold_full[[97]][[i]][["test"]]
  
  # Subset the dtrain using the fold indices
  train_set <- dtrain[train_indices, ]
  test_set <- dtrain[test_indices, ]
  
  # Train the model on the training set
  model <- xgb.train(params = params, data = train_set, nrounds = 100)
  
  # Store the trained model
  t1_models[[i]] <- model
  
  # Make predictions on the test set using the trained model
  predictions <- predict(t1_models[[i]], newdata = test_set)
  
  # Store the predictions for this fold
  all_predictions[[i]] <- predictions
  
  actual <- data[test_indices, ]$target
  
  rmse <- sqrt(mean((actual - predictions)^2))
  mape <- mean(abs((actual - predictions) / actual)) * 100
  smape <- mean(2 * abs(actual - predictions) / (abs(actual) + abs(predictions))) * 100
  
  # Store the performance metrics for this fold
  all_rmse[i] <- rmse
  all_mape[i] <- mape
  all_smape[i] <- smape
}

# Aggregate the performance metrics (e.g., mean RMSE and MAPE)
mean_rmse <- mean(all_rmse)
mean_mape <- mean(all_mape)
mean_smape = mean(all_smape)

# Print the performance metrics
cat("Mean RMSE:", mean_rmse, "\n")
cat("Mean MAPE:", mean_mape, "\n")
cat("Mean SMAPE:", mean_smape, "\n")

```

```{r RQ1 : Plot Validation}
# Create a data frame with the evaluation metrics for each fold
metrics_df <- data.frame(
  Fold = 1:length(all_rmse),
  RMSE = all_rmse,
  MAPE = all_mape,
  SMAPE = all_smape
)

# Reshape the data frame to long format for plotting
metrics_long <- tidyr::pivot_longer(metrics_df, cols = -Fold, names_to = "Metric", values_to = "Value")

# Plot the evaluation metrics
ggplot(metrics_long, aes(x = Fold, y = Value, color = Metric)) +
  geom_line() +
  labs(title = "Evaluation Metrics Across Folds", y = "Metric Value", color = "Metric") +
  theme_minimal()

```



```{r RQ2 : }


```

```{r Model 2 : Churn Train/Test Split}
# Sort the data frame by date in ascending order
split_da_profiles <- lapply(da_profiles, function(df) {
  sorted_df <- df[order(df$date), ]
  sorted_df$weekday <- as.numeric(factor(sorted_df$weekday)) - 1
  sorted_df$churn_status <- as.numeric(factor(sorted_df$churn_status)) - 1
  
  split_index <- ceiling(0.7 * nrow(sorted_df))
  
  train_df <- sorted_df[1:split_index, ]
  test_df <- sorted_df[(split_index + 1):nrow(sorted_df), ]
  
  return(list(train_df = train_df, test_df = test_df))
})


```

```{r Model 2 : Churn Train}
# OBJ = binary:logitraw, binary:hinge, binary:logitboost, binary:logloss

# Train individual models for each profile
profile_binary_models <- list()
profile_regression_models = list()

for (i in 1:length(split_da_profiles)) {
  profile <- split_da_profiles[[i]]
  
  # Extract the train and test data for the current profile
  train_df <- profile$train
  test_df <- profile$test
  
  # Define the features and target variable
  model_binary_features <- c("year", "month.x", "day_of_year", "week", "weekday", "days_since_achievement", "n")
  model_binary_target <- "churn_status"
  
  model_regression_features <- c("year", "month.x", "day_of_year", "week", "weekday", "n")
  model_regression_target <- "days_since_achievement"
  
  # Convert the train data to a matrix
  train_binary_matrix <- as.matrix(train_df[, model_binary_features])
  train_regression_matrix <- as.matrix(train_df[, model_regression_features])
  
  test_binary_matrix <- as.matrix(test_df[, model_binary_features])
  test_regression_matrix <- as.matrix(test_df[, model_regression_features])
  
  # Create the DMatrix for training
  dtrain_binary <- xgb.DMatrix(data = train_binary_matrix, label = train_df[[model_binary_target]])
  dtrain_regression <- xgb.DMatrix(data = train_regression_matrix, label = train_df[[model_regression_target]])
  
  dtest_binary <- xgb.DMatrix(data = test_binary_matrix, label = test_df[[model_binary_target]])
  dtest_regression <- xgb.DMatrix(data = test_regression_matrix, label = test_df[[model_regression_target]])
  
  # Set the hyperparameters for the XGBoost model
  binary_params <- list(
    objective = "binary:logistic",  # Binary classification task
    max_depth = 6,  # Maximum tree depth
    eta = 0.1,  # Learning rate
    subsample = 0.8,  # Subsample ratio
    colsample_bytree = 0.8  # Feature subsampling ratio
  )
  
  regression_params = list(
    objective = "reg:squarederror",  # Regression task
    max_depth = 6,  # Maximum tree depth
    eta = 0.1,  # Learning rate
    subsample = 0.8,  # Subsample ratio
    colsample_bytree = 0.8  # Feature subsampling ratio
  )
  
  # Train the XGBoost model
  binary_model <- xgb.train(params = binary_params, data = dtrain_binary, nrounds = 100)
  regression_model <- xgb.train(params = regression_params, data = dtrain_regression, nrounds = 100)
  
  # Store the trained models
  profile_binary_models[[i]] = binary_model
  profile_regression_models[[i]] = regression_model
}


```

```{r Model 2 : Churn Predictions}
# Initialize lists to store predictions and actual values
all_binary_predictions <- list()
all_regression_predictions <- list()

all_binary_actuals <- list()
all_regression_actuals = list()

# Iterate over the models and make predictions
for (i in 1:length(profile_binary_models)) {
  # Get the current binary classification and regression models, and test data for the profile
  binary_model <- profile_binary_models[[i]]
  regression_model <- profile_regression_models[[i]]
  test_df <- split_da_profiles[[i]]$test
  
  # Define the binary classification features and target variable
  binary_features <- c("year", "month.x", "day_of_year", "week", "weekday", "days_since_achievement", "n")
  binary_target <- "churn_status"
  
  # Define the regression features and target variable
  regression_features <- c("year", "month.x", "day_of_year", "week", "weekday", "n")
  regression_target <- "days_since_achievement"
  
  # Convert the test data to matrices
  binary_matrix <- as.matrix(test_df[, binary_features])
  regression_matrix <- as.matrix(test_df[, regression_features])
  
  # Create the DMatrix for prediction
  dbinary <- xgb.DMatrix(data = binary_matrix)
  dregression <- xgb.DMatrix(data = regression_matrix)
  
  # Make predictions using the models
  binary_predictions <- predict(binary_model, dbinary)
  regression_predictions <- predict(regression_model, dregression)
  
  # Store the predictions and actual values
  all_binary_predictions[[i]] <- binary_predictions
  all_regression_predictions[[i]] <- regression_predictions
  
  all_binary_actuals[[i]] <- test_df[[binary_target]]
  all_regression_actuals[[i]] <- test_df[[regression_target]]
}

# Apply threshold to convert binary probabilities to class labels
all_binary_predicted_labels <- lapply(all_binary_predictions, function(pred) ifelse(pred > 0.5, 1, 0))


```

```{r Model 2 : Churn Evaluate}

confusion_matrices <- lapply(1:length(all_binary_predicted_labels), function(i) {
  predicted <- factor(all_binary_predicted_labels[[i]], levels = c(0, 1), labels = c("Active", "Churned"))
  actual <- factor(all_actuals[[i]], levels = c(0, 1), labels = c("Active", "Churned"))
  confusionMatrix(predicted, actual)
})

evaluation_metrics <- lapply(confusion_matrices, function(cm) {
  cm_summary <- cm$byClass
  return(cm_summary)
})

# Initialize lists to store evaluation metrics
regression_eval_metrics <- list()

# Iterate over the regression predictions and actual values
for (i in 1:length(all_regression_predictions)) {
  # Get the current regression predictions and actual values
  predictions <- all_regression_predictions[[i]]
  actuals <- all_regression_actuals[[i]]
  
  # Calculate evaluation metrics
  mae <- mean(abs(predictions - actuals))
  rmse <- sqrt(mean((predictions - actuals)^2))
  
  # Store the evaluation metrics
  regression_eval_metrics[[i]] <- list(MAE = mae, RMSE = rmse, R_squared = r_squared)
}

# Print the evaluation metrics
for (i in 1:length(regression_eval_metrics)) {
  cat("Profile", i, "Evaluation Metrics:\n")
  cat("MAE:", regression_eval_metrics[[i]]$MAE, "\n")
  cat("RMSE:", regression_eval_metrics[[i]]$RMSE, "\n")
}


```


```{r Model 2 : Forecast}
for (i in 1:length(split_da_profiles)) {
  profile <- split_da_profiles[[i]]
  
  # Extract the train and test data for the current profile
  train_df <- profile$train
  test_df <- profile$test
  
  # Create time series objects for the train and test data
  train_ts <- ts(train_df$churn_status)
  test_ts <- ts(test_df$churn_status)
  
  # Build the forecasting model
  model <- auto.arima(train_ts)
  
  # Make predictions
  forecast <- forecast(model, h = length(test_ts))
  
  # Print the forecasted values
  print(forecast)
}

```







